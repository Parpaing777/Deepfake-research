{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP20lTLbAjzyXAKVPYXxa0o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"08QIWHXHu5z9","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f046f6d6-3bd9-464b-f39e-05e38ed5d514","executionInfo":{"status":"error","timestamp":1736674824246,"user_tz":-60,"elapsed":26659,"user":{"displayName":"abdeldjebbar abid","userId":"05970389026271228350"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-1-8cf433399327>\", line 47, in <cell line: 47>\n","    videos_real = [os.path.join(real_video_dir, f) for f in os.listdir(real_video_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/reals'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1624, in getframeinfo\n","    lines, lnum = findsource(frame)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 170, in findsource\n","    file = getsourcefile(object) or getfile(object)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 869, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-1-8cf433399327>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Extraire tous les chemins des vidÃ©os des dossiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mvideos_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_video_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_video_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.avi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.mov'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mvideos_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_video_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_video_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.avi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.mov'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/reals'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'FileNotFoundError' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}],"source":["# Installation des bibliothÃ¨ques nÃ©cessaires\n","!pip install opencv-python-headless scikit-learn numpy matplotlib\n","\n","import cv2\n","import numpy as np\n","import os\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","\n","# 1. PrÃ©paration des donnÃ©es : extraction de frames et dÃ©tection de visages\n","def extract_faces_from_videos(video_paths, output_dir, frames_per_video=5):\n","    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for video_path in video_paths:\n","        cap = cv2.VideoCapture(video_path)\n","        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        frame_interval = max(1, frame_count // frames_per_video)\n","\n","        video_name = os.path.splitext(os.path.basename(video_path))[0]\n","        count = 0\n","\n","        for i in range(frames_per_video):\n","            cap.set(cv2.CAP_PROP_POS_FRAMES, i * frame_interval)\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n","\n","            for j, (x, y, w, h) in enumerate(faces):\n","                face = frame[y:y + h, x:x + w]\n","                face_path = os.path.join(output_dir, f\"{video_name}_face_{count}.jpg\")\n","                cv2.imwrite(face_path, face)\n","                count += 1\n","\n","        cap.release()\n","\n","# DÃ©finir les chemins des dossiers contenant les vidÃ©os\n","real_video_dir = \"/content/drive/MyDrive/Colab Notebooks/reals\"\n","fake_video_dir = \"/content/drive/MyDrive/Colab Notebooks/fakes\"\n","\n","# Extraire tous les chemins des vidÃ©os des dossiers\n","videos_real = [os.path.join(real_video_dir, f) for f in os.listdir(real_video_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n","videos_fake = [os.path.join(fake_video_dir, f) for f in os.listdir(fake_video_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n","\n","# Extraire les visages des vidÃ©os\n","# extract_faces_from_videos(videos_real, \"/content/drive/MyDrive/Colab Notebooks/real_faces\")\n","# extract_faces_from_videos(videos_fake, \"/content/drive/MyDrive/Colab Notebooks/fake_faces\")\n","\n","\n","# 2. Extraction des caractÃ©ristiques basÃ©es sur le bruit\n","def extract_noise_features(image_path):\n","    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    if image is None:\n","        return None\n","\n","    noise = image - cv2.GaussianBlur(image, (5, 5), 0)\n","    features = [\n","        np.mean(noise),\n","        np.var(noise),\n","        np.median(noise),\n","        np.percentile(noise, 10),\n","        np.percentile(noise, 90)\n","    ]\n","    return features\n","\n","def prepare_dataset(real_dir, fake_dir):\n","    X, y = [], []\n","\n","    for file_name in os.listdir(real_dir):\n","        file_path = os.path.join(real_dir, file_name)\n","        features = extract_noise_features(file_path)\n","        if features:\n","            X.append(features)\n","            y.append(0)  # Label for real\n","\n","    for file_name in os.listdir(fake_dir):\n","        file_path = os.path.join(fake_dir, file_name)\n","        features = extract_noise_features(file_path)\n","        if features:\n","            X.append(features)\n","            y.append(1)  # Label for fake\n","\n","    return np.array(X), np.array(y)\n","\n","# 3. Apprentissage supervisÃ© avec Random Forest\n","def train_and_evaluate(X, y):\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n","    clf.fit(X_train, y_train)\n","\n","    y_pred = clf.predict(X_test)\n","\n","    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n","\n","    return clf\n","\n","# Exemple complet d'exÃ©cution\n","real_faces_dir = \"/content/drive/MyDrive/Colab Notebooks/real_faces\"\n","fake_faces_dir = \"/content/drive/MyDrive/Colab Notebooks/fake_faces\"\n","\n","# Assurez-vous d'avoir extrait les visages au prÃ©alable\n","# extract_faces_from_videos(videos_real, real_faces_dir)\n","# extract_faces_from_videos(videos_fake, fake_faces_dir)\n","\n","X, y = prepare_dataset(real_faces_dir, fake_faces_dir)\n","clf = train_and_evaluate(X, y)\n","\n","import joblib\n","joblib.dump(clf, \"/content/drive/MyDrive/Colab Notebooks/model.pkl\")\n","\n"]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import os\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import joblib\n","\n","\n","\n","def extract_faces_from_videos(video_paths, output_dir, frames_per_video=5):\n","    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for video_path in video_paths:\n","        cap = cv2.VideoCapture(video_path)\n","        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        frame_interval = max(1, frame_count // frames_per_video)\n","\n","        video_name = os.path.splitext(os.path.basename(video_path))[0]\n","        count = 0\n","\n","        for i in range(frames_per_video):\n","            cap.set(cv2.CAP_PROP_POS_FRAMES, i * frame_interval)\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n","\n","            for j, (x, y, w, h) in enumerate(faces):\n","                face = frame[y:y + h, x:x + w]\n","                face_path = os.path.join(output_dir, f\"{video_name}_face_{count}.jpg\")\n","                cv2.imwrite(face_path, face)\n","                count += 1\n","\n","        cap.release()\n","\n","# 2. Extraction des caractÃ©ristiques basÃ©es sur le bruit\n","def extract_noise_features(image_path):\n","    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    if image is None:\n","        return None\n","\n","    noise = image - cv2.GaussianBlur(image, (5, 5), 0)\n","    features = [\n","        np.mean(noise),\n","        np.var(noise),\n","        np.median(noise),\n","        np.percentile(noise, 10),\n","        np.percentile(noise, 90)\n","    ]\n","    return features\n","# Charger le modÃ¨le sauvegardÃ©\n","clf = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/model.pkl\")\n","\n","# Dossier contenant les vidÃ©os de test\n","test_video_dir = \"/content/drive/MyDrive/Colab Notebooks/video_test\"\n","test_faces_dir = \"/content/drive/MyDrive/Colab Notebooks/test_faces\"\n","\n","# Ãtape 1 : Extraire les visages des vidÃ©os de test\n","os.makedirs(test_faces_dir, exist_ok=True)\n","test_videos = [os.path.join(test_video_dir, f) for f in os.listdir(test_video_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n","# extract_faces_from_videos(test_videos, test_faces_dir)\n","\n","# Ãtape 2 : PrÃ©dire pour chaque vidÃ©o\n","results = {}\n","for video in test_videos:\n","    video_name = os.path.splitext(os.path.basename(video))[0]\n","    video_faces = [os.path.join(test_faces_dir, f) for f in os.listdir(test_faces_dir) if f.startswith(video_name)]\n","\n","    if not video_faces:\n","        results[video_name] = \"Pas de visage dÃ©tectÃ©\"\n","        continue\n","\n","    # Extraire les caractÃ©ristiques des visages\n","    features = [extract_noise_features(face) for face in video_faces]\n","    features = [f for f in features if f is not None]  # Exclure les erreurs d'extraction\n","\n","    if not features:\n","        results[video_name] = \"Pas de caractÃ©ristiques extraites\"\n","        continue\n","\n","    # PrÃ©dire pour chaque visage\n","    predictions = clf.predict(features)\n","\n","    # DÃ©terminer le label final (majoritÃ© des prÃ©dictions)\n","    final_prediction = \"vrai\" if np.mean(predictions) < 0.5 else \"fake\"\n","    results[video_name] = final_prediction\n","\n","# Ãtape 3 : Afficher les rÃ©sultats\n","for video_name, prediction in results.items():\n","    print(f\"VidÃ©o : {video_name} - RÃ©sultat : {prediction}\")\n","\n","\n","\n","\n","# VidÃ©o : 14_15__hugging_happy__3FRJCJ0V - RÃ©sultat : fake\n","# VidÃ©o : 07_21__outside_talking_still_laughing__K7KXUHMU - RÃ©sultat : fake\n","# VidÃ©o : 11_06__outside_talking_pan_laughing__MX659QU8 - RÃ©sultat : fake\n","# VidÃ©o : 12_06__outside_talking_still_laughing__3K21NFNM - RÃ©sultat : fake\n","# VidÃ©o : 06_14__walking_down_indoor_hall_disgust__8U9ULZDT - RÃ©sultat : fake\n","# VidÃ©o : 27__walking_down_street_outside_angry - RÃ©sultat : vrai\n","# VidÃ©o : 22__secret_conversation - RÃ©sultat : vrai\n","# VidÃ©o : 08__outside_talking_still_laughing - RÃ©sultat : vrai\n","# VidÃ©o : 10__talking_angry_couch - RÃ©sultat : vrai\n","# VidÃ©o : 24__talking_angry_couch - RÃ©sultat : vrai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2fqildqVLxH","executionInfo":{"status":"ok","timestamp":1734016053863,"user_tz":-60,"elapsed":1573,"user":{"displayName":"abdeldjebbar abid","userId":"05970389026271228350"}},"outputId":"a85773e6-6d55-4b67-8388-d721aba0c9ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VidÃ©o : 14_15__hugging_happy__3FRJCJ0V - RÃ©sultat : fake\n","VidÃ©o : 07_21__outside_talking_still_laughing__K7KXUHMU - RÃ©sultat : fake\n","VidÃ©o : 11_06__outside_talking_pan_laughing__MX659QU8 - RÃ©sultat : fake\n","VidÃ©o : 12_06__outside_talking_still_laughing__3K21NFNM - RÃ©sultat : fake\n","VidÃ©o : 06_14__walking_down_indoor_hall_disgust__8U9ULZDT - RÃ©sultat : fake\n","VidÃ©o : 27__walking_down_street_outside_angry - RÃ©sultat : vrai\n","VidÃ©o : 22__secret_conversation - RÃ©sultat : vrai\n","VidÃ©o : 08__outside_talking_still_laughing - RÃ©sultat : vrai\n","VidÃ©o : 10__talking_angry_couch - RÃ©sultat : vrai\n","VidÃ©o : 24__talking_angry_couch - RÃ©sultat : vrai\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"_yxdOMit08kV","executionInfo":{"status":"ok","timestamp":1736683017159,"user_tz":-60,"elapsed":29719,"user":{"displayName":"abdeldjebbar abid","userId":"05970389026271228350"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb5da36a-26c5-485a-c319-9abc9315aad5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}]}